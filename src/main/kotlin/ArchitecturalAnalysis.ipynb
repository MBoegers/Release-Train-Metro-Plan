{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Release Train Metro Plan Analysis\n\nThis notebook analyzes project relationships and generates visualization data for the release train metro plan.\n\n## Data Sources\n\nThe analysis uses three main data sources from OpenRewrite recipe runs:\n- **ProjectCoordinates.csv**: Maven/Gradle project identifiers (groupId, artifactId) \n- **DependenciesInUse.csv**: Dependencies between projects\n- **ParentRelationships.csv**: Parent POM and Gradle parent project relationships\n- **UnusedDependencies.csv**: Import patterns to identify potentially unused dependencies\n\n## Visualization Link Types\n\nThe generated metro plan visualization supports multiple connection types:\n- **Dependency links** (blue solid): Normal dependencies between projects\n- **Parent links** (red solid): Parent POM or Gradle parent relationships  \n- **Unused links** (orange dashed): Potentially unused dependencies that should be reviewed\n\nRun the enhanced `ReleaseMetroPlan` recipe to generate all data files, then execute this notebook to create the visualization data."
  },
  {
   "cell_type": "markdown",
   "source": "# Release Train Metro Plan Analysis\n\nThis notebook analyzes project relationships and generates visualization data for the release train metro plan.\n\n## Data Sources\n\nThe analysis uses three main data sources from OpenRewrite recipe runs:\n- **ProjectCoordinates.csv**: Maven/Gradle project identifiers (groupId, artifactId) \n- **DependenciesInUse.csv**: Dependencies between projects\n- **ParentRelationships.csv**: Parent POM and Gradle parent project relationships",
   "metadata": {}
  },
  {
   "metadata": {
    "executionRelatedData": {
     "compiledClasses": [
      "Line_59_jupyter",
      "Line_57_jupyter",
      "Line_75_jupyter",
      "Line_58_jupyter",
      "Line_9_jupyter",
      "Line_60_jupyter",
      "Line_74_jupyter",
      "Line_18_jupyter",
      "Line_7_jupyter",
      "Line_55_jupyter",
      "Line_56_jupyter",
      "Line_10_jupyter",
      "Line_8_jupyter",
      "Line_19_jupyter",
      "Line_69_jupyter",
      "Line_6_jupyter",
      "Line_68_jupyter",
      "Line_54_jupyter",
      "Line_3_jupyter",
      "Line_20_jupyter",
      "Line_66_jupyter",
      "Line_80_jupyter",
      "Line_67_jupyter",
      "Line_5_jupyter",
      "Line_65_jupyter",
      "Line_4_jupyter",
      "Line_78_jupyter",
      "Line_17_jupyter",
      "Line_79_jupyter",
      "Line_16_jupyter",
      "Line_64_jupyter",
      "Line_15_jupyter",
      "Line_76_jupyter",
      "Line_14_jupyter",
      "Line_63_jupyter",
      "Line_77_jupyter",
      "Line_84_jupyter",
      "Line_85_jupyter",
      "Line_86_jupyter",
      "Line_87_jupyter",
      "Line_88_jupyter",
      "Line_89_jupyter",
      "Line_90_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "val thisRepo = \"/Users/matt/projects/mboegers/Release-Train-Metro-Plan\"\n",
    "\n",
    "val workspace = \"/Users/matt/workspaces/moderne-migration-workspace\"\n",
    "val recipeRun = \"20251230102718-myVSI\"\n",
    "\n",
    "//val workspace = \"/Users/matt/workspaces/app.moderne.io/Netflix_Spring_Apache\"\n",
    "//val recipeRun = \"20251217101017-MOHFU\"\n",
    "\n",
    "val projectIds = DataFrame.read(\"${workspace}/.moderne/run/${recipeRun}/datatables/dev.mboegie.rewrite.releasemetro.table.ProjectCoordinates.csv\")\n",
    "val dependencies = DataFrame.read(\"${workspace}/.moderne/run/${recipeRun}/datatables/org.openrewrite.maven.table.DependenciesInUse.csv\")\n",
    "val parentRelationships = DataFrame.read(\"${workspace}/.moderne/run/${recipeRun}/datatables/dev.mboegie.rewrite.releasemetro.table.ParentRelationships.csv\")\n",
    "\n",
    "print(\"Loaded ${projectIds.rowsCount()} projects, ${dependencies.rowsCount()} dependencies, and ${parentRelationships.rowsCount()} parent relationships.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "executionRelatedData": {
     "compiledClasses": [
      "Line_31_jupyter",
      "Line_21_jupyter",
      "Line_70_jupyter",
      "Line_81_jupyter",
      "Line_91_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "import java.nio.file.Files\n",
    "import java.nio.file.StandardOpenOption\n",
    "import kotlin.io.path.Path\n",
    "import kotlin.io.path.createFile\n",
    "\n",
    "data class Artifact(val group: String?,\n",
    "                   val artifact: String,\n",
    "                   var parent: Artifact? = null) {\n",
    "    override fun equals(other: Any?): Boolean = other is Artifact && other.group == group && other.artifact == artifact\n",
    "    override fun hashCode(): Int = group.hashCode() * 31 + artifact.hashCode()\n",
    "}\n",
    "\n",
    "data class Repository(val path: String, val artifacts: Set<Artifact>,  val dependencies: Set<Artifact>) {\n",
    "    override fun equals(other: Any?): Boolean = other is Repository && other.path == path\n",
    "    override fun hashCode(): Int = path.hashCode()\n",
    "}\n",
    "\n",
    "val repos = mutableListOf<Repository>()\n",
    "\n",
    "// Create repositories from project coordinates\n",
    "projectIds\n",
    "    .select { it[\"repositoryPath\", \"repositoryBranch\", \"groupId\", \"artifactId\"] }\n",
    "    .filter { it[\"repositoryBranch\"] == \"master\" || it[\"repositoryBranch\"] == \"main\" }\n",
    "    .groupBy { it[\"repositoryPath\"] }\n",
    "    .forEach { groupEntry ->\n",
    "        val repoPath = groupEntry.key[\"repositoryPath\"] as String\n",
    "        val repoGroup = groupEntry.group\n",
    "        \n",
    "        val repoArtifacts = repoGroup\n",
    "            .map { row -> Artifact(row[\"groupId\"] as String?, row[\"artifactId\"] as String) }\n",
    "            .toSet()\n",
    "        \n",
    "        val repoDependencies = dependencies\n",
    "            .select { it[\"repositoryPath\", \"repositoryBranch\", \"groupId\", \"artifactId\"] }\n",
    "            .filter { it[\"repositoryBranch\"] == \"master\" || it[\"repositoryBranch\"] == \"main\" }\n",
    "            .filter { it[\"repositoryPath\"] == repoPath }\n",
    "            .map { row -> Artifact(row[\"groupId\"] as String?, row[\"artifactId\"] as String) }\n",
    "            .toSet()\n",
    "        \n",
    "        repos.add(Repository(repoPath, repoArtifacts, repoDependencies))\n",
    "    }\n",
    "\n",
    "// Process parent relationships from the new ParentRelationships DataTable\n",
    "if(parentRelationships.rowsCount() < 0) {\n",
    "    parentRelationships\n",
    "        .select { it[\"repositoryPath\", \"repositoryBranch\", \"childArtifactId\", \"parentGroupId\", \"parentArtifactId\"] }\n",
    "        .filter { it[\"repositoryBranch\"] == \"master\" || it[\"repositoryBranch\"] == \"main\" }\n",
    "        .forEach { row ->\n",
    "            repos.firstOrNull { r -> r.path == row[\"repositoryPath\"] as String }\n",
    "                ?.artifacts?.firstOrNull { a -> a.artifact == row[\"childArtifactId\"] as String }\n",
    "                ?.let { a -> a.parent = Artifact(row[\"parentGroupId\"] as String?, row[\"parentArtifactId\"] as String) }\n",
    "        }\n",
    "} else {\n",
    "    println(\"No parent relationships found - skipping parent relationship processing\")\n",
    "}\n",
    "\n",
    "println(\"derived ${repos.size} repositories from the data, containing ${repos.sumOf { it.artifacts.size }} artifacts, ${repos.sumOf { it.dependencies.size }} dependencies, and ${repos.sumOf { r -> r.artifacts.count { it.parent != null } }} parent relationships.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "executionRelatedData": {
     "compiledClasses": [
      "Line_62_jupyter",
      "Line_71_jupyter",
      "Line_82_jupyter",
      "Line_92_jupyter"
     ]
    }
   },
   "cell_type": "code",
   "source": [
    "import java.nio.file.Path\n",
    "import java.nio.file.Paths\n",
    "import kotlin.io.path.listDirectoryEntries\n",
    "import kotlin.io.path.name\n",
    "\n",
    "// Generate connections between repositories including parent relationships and unused dependencies\n",
    "enum class LinkType { parent, dependency, unused }\n",
    "data class Link(val src: String, val dist: String, val type: LinkType) {\n",
    "    fun asD3() : String = \"{ source: \\\"${src}\\\", target: \\\"${dist}\\\", type: \\\"${type}\\\" }\"\n",
    "}\n",
    "data class Node(val id: String) {\n",
    "    fun asD3() : String = \"{ id: \\\"${id}\\\" }\"\n",
    "}\n",
    "\n",
    "val edges = mutableSetOf<Link>()\n",
    "\n",
    "for (repo in repos) {\n",
    "    // Add parent relationships: if artifact A has parent B, create link from A's repo to B's repo\n",
    "    for (artifact in repo.artifacts) {\n",
    "        if (artifact.parent != null) {\n",
    "            val parentRepo = repos.find { it.artifacts.contains(artifact.parent) }\n",
    "            if (parentRepo != null && parentRepo.path != repo.path) {\n",
    "                edges.add(Link(repo.path, parentRepo.path, LinkType.parent))\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Add dependency relationships: if repo uses dependency D, create link from repo to D's repo\n",
    "    repo.dependencies\n",
    "        .map { dep -> repos.find { it.artifacts.contains(dep) }?.path }\n",
    "        .filterNotNull()\n",
    "        .filter { it != repo.path }\n",
    "        .map { Link(repo.path, it, LinkType.dependency) }\n",
    "        .forEach { edges.add(it) }\n",
    "}\n",
    "\n",
    "// Add unused dependency relationships if UnusedDependencies data is available\n",
    "try {\n",
    "    val unusedDeps = DataFrame.read(\"${workspace}/.moderne/run/${recipeRun}/datatables/dev.mboegie.rewrite.releasemetro.table.UnusedDependencies.csv\")\n",
    "    \n",
    "    // Group unused dependencies by repository and find potential unused links\n",
    "    val unusedByRepo = unusedDeps\n",
    "        .groupBy { it[\"repositoryPath\"] }\n",
    "        .map { groupEntry ->\n",
    "            val repoPath = groupEntry.key[\"repositoryPath\"] as String\n",
    "            val group = groupEntry.group\n",
    "            val dependencies = group\n",
    "                .filter { it[\"reasonSuspected\"]?.toString()?.contains(\"Import found\") == true }\n",
    "                .groupBy { it[\"dependencyGroupId\"] }\n",
    "                .filter { it.group().size().ncol < 2 } // Dependencies with very few imports\n",
    "                .keys\n",
    "            \n",
    "            repoPath to dependencies\n",
    "        }\n",
    "        .toMap()\n",
    "    \n",
    "    // Create unused dependency links for dependencies with minimal usage\n",
    "    for ((repoPath, suspiciousDeps) in unusedByRepo) {\n",
    "        for (depGroupId in suspiciousDeps) {\n",
    "            val targetRepo = repos.find { repo -> \n",
    "                repo.artifacts.any { it.group == depGroupId.get(0) }\n",
    "            }?.path\n",
    "            \n",
    "            if (targetRepo != null && targetRepo != repoPath) {\n",
    "                // Only add if there's already a dependency link (to avoid false positives)\n",
    "                val existingDep = edges.find { \n",
    "                    it.src == repoPath && it.dist == targetRepo && it.type == LinkType.dependency \n",
    "                }\n",
    "                if (existingDep != null) {\n",
    "                    edges.add(Link(repoPath, targetRepo, LinkType.unused))\n",
    "                    println(\"Added unused dependency link: $repoPath -> $targetRepo ($depGroupId)\")\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    println(\"Processed ${unusedByRepo.size} repositories for unused dependency analysis\")\n",
    "    \n",
    "} catch (e: Exception) {\n",
    "    println(\"UnusedDependencies.csv not available - skipping unused dependency link generation\")\n",
    "    println(\"Run FindPotentiallyUnusedDependencies recipe to enable unused dependency analysis\")\n",
    "}\n",
    "\n",
    "val nodes = edges.map { listOf(it.src, it.dist) }.flatMap { it }.distinct().map { Node(it) }\n",
    "\n",
    "println(\"\\nGenerated ${edges.size} total connections:\")\n",
    "println(\"- ${edges.count { it.type == LinkType.dependency }} dependency links\")\n",
    "println(\"- ${edges.count { it.type == LinkType.parent }} parent links\") \n",
    "println(\"- ${edges.count { it.type == LinkType.unused }} unused dependency links\")\n",
    "\n",
    "//println(nodes.joinToString(\",\\n\\t\", prefix = \"const nodes = [\\n\", postfix = \"\\n];\") { it.asD3() })\n",
    "//println(edges.joinToString(\",\\n\\t\", prefix = \"const links = [\\n\", postfix = \"\\n];\") { it.asD3() })\n",
    "\n",
    "Files.writeString(Path(\"${thisRepo}/src/main/static/data/connections.js\"),\n",
    "        nodes.joinToString(\",\\n\\t\", prefix = \"const nodes = [\\n\", postfix = \"\\n];\") { it.asD3() } + \"\\n\" +\n",
    "        edges.joinToString(\",\\n\\t\", prefix = \"const links = [\\n\", postfix = \"\\n];\") { it.asD3() },\n",
    "    StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Using the Enhanced Visualization\n\nAfter running this notebook, copy the generated JavaScript output to `connections.js` and open `metro-plan.html` in a browser.\n\n### Visual Legend:\n- **Blue solid lines + arrows**: Regular dependency relationships  \n- **Red solid lines + arrows**: Parent POM/Gradle relationships\n- **Orange dashed lines + arrows**: Potentially unused dependencies (review candidates)\n\n### Interpreting Unused Dependencies:\nOrange dashed lines indicate dependencies that are declared in build files but have minimal import usage in the source code. These represent potential cleanup opportunities:\n\n1. **Review the dependency**: Check if it's actually needed\n2. **Consider removal**: If unused, removing it can simplify the release train\n3. **Update build files**: Remove unnecessary dependencies to reduce coupling\n\nThe dashed visualization makes it easy to spot problematic dependencies that may be complicating your release coordination.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "// Analyze unused dependencies (if UnusedDependencies.csv is available)\n",
    "// This would be generated by running the FindPotentiallyUnusedDependencies recipe\n",
    "\n",
    "try {\n",
    "    val unusedDeps = DataFrame.read(\"${workspace}/.moderne/run/${recipeRun}/datatables/dev.mboegie.rewrite.releasemetro.table.UnusedDependencies.csv\")\n",
    "    \n",
    "    println(\"=== Unused Dependencies Analysis ===\")\n",
    "    println(\"Found ${unusedDeps.rowsCount()} import usage records\")\n",
    "    \n",
    "    // Group by dependency to see usage patterns\n",
    "    val dependencyUsage = unusedDeps\n",
    "        .groupBy { it[\"dependencyGroupId\"] }\n",
    "        .aggregate {\n",
    "            count() into \"usageCount\"\n",
    "            it[\"dependencyArtifactId\"].get(0) into \"artifactId\"\n",
    "        }\n",
    "        .sortByDesc(\"usageCount\")\n",
    "    \n",
    "    println(\"\\nMost imported dependency groups:\")\n",
    "    dependencyUsage.take(10).forEach { row ->\n",
    "        println(\"${row[\"dependencyGroupId\"]}: ${row[\"usageCount\"]} imports\")\n",
    "    }\n",
    "    \n",
    "    // Identify potentially problematic dependencies\n",
    "    val suspiciousDeps = unusedDeps\n",
    "        .filter { it[\"reasonSuspected\"]?.toString()?.contains(\"Import found\") == true }\n",
    "        .groupBy { it[\"dependencyGroupId\"] }\n",
    "        .aggregate { count() into \"importCount\" }\n",
    "        .filter { (it[\"importCount\"] as? Int ?: 0) < 3 } // Dependencies with very few imports\n",
    "    \n",
    "    println(\"\\nDependencies with minimal usage (< 3 imports):\")\n",
    "    suspiciousDeps.forEach { row ->\n",
    "        println(\"${row[\"dependencyGroupId\"]}: ${row[\"importCount\"]} imports\")\n",
    "    }\n",
    "    \n",
    "} catch (e: Exception) {\n",
    "    println(\"UnusedDependencies.csv not found - run FindPotentiallyUnusedDependencies recipe first\")\n",
    "    println(\"This analysis shows import patterns that can help identify unused dependencies\")\n",
    "}"
   ],
   "metadata": {
    "executionRelatedData": {
     "compiledClasses": [
      "Line_73_jupyter",
      "Line_83_jupyter",
      "Line_72_jupyter",
      "Line_93_jupyter"
     ]
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  },
  "ktnbPluginMetadata": {
   "sessionRunMode": "IDE_PROCESS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
